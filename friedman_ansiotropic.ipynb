{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from sklearn.datasets import make_friedman1, make_friedman2, make_friedman3\n",
    "from scipy import optimize\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise=0.15\n",
    "norm=True\n",
    "ntk_depth = (3, 100)\n",
    "c_val_bounds = (0.0001, 10**5)#'fixed'\n",
    "corrcoef_type='p'\n",
    "opt_resets=10\n",
    "def bnds(p=1, n=10):\n",
    "    return tuple((0.0001, 10**p) for i in range(0, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_init, y_init = make_friedman3(noise=noise, random_state=18397425)\n",
    "datasets = processing(X_init, y_init)\n",
    "\n",
    "X, y, X_train, y_train = [None, datasets['orig'][1], None, datasets['orig train'][1]]\n",
    "\n",
    "if norm:\n",
    "    X = datasets['norm'][0]\n",
    "    X_train = datasets['norm train'][0]\n",
    "else:\n",
    "    X = datasets['orig'][0]\n",
    "    X_train = datasets['orig train'][0]\n",
    "\n",
    "n = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTK 1    :  2.34**2 * NTK(depth=3, c=2.000, bias=0.550) + WhiteKernel(noise_level=0.117)\n",
      "NTK 2    :  0.146**2 * NTK(depth=100, c=2.000, bias=0.000) + WhiteKernel(noise_level=0.0605)\n"
     ]
    }
   ],
   "source": [
    "if noise != 0.0:\n",
    "    ntk_1 = (\n",
    "        ConstantKernel(\n",
    "            constant_value=1, \n",
    "            constant_value_bounds=(1e-9, 1e2)\n",
    "        ) * \n",
    "        NTK(depth=ntk_depth[0], c=2, \n",
    "            bias=1e-1, \n",
    "            bias_bounds=(1e-9, 1e0)\n",
    "        ) + WhiteKernel()\n",
    "    )\n",
    "\n",
    "    ntk_2 = (\n",
    "        ConstantKernel(\n",
    "            constant_value=1, \n",
    "            constant_value_bounds=(1e-9, 1e2)\n",
    "        ) * \n",
    "        NTK(depth=ntk_depth[1], c=2, \n",
    "            bias=1e-1, \n",
    "            bias_bounds=(1e-9, 1e0)\n",
    "        ) + WhiteKernel()\n",
    "    )\n",
    "\n",
    "    lpk = (\n",
    "        ConstantKernel(\n",
    "            constant_value=0.224**2, \n",
    "            constant_value_bounds=c_val_bounds\n",
    "        ) * \n",
    "        Matern(\n",
    "            nu=1/2,\n",
    "            length_scale=np.array([1,1,1,1,1,1,1,1,1,1]), # anisotropic trueA\n",
    "            # length_scale=1,\n",
    "            length_scale_bounds='fixed'#(1e-1, 1e3), \n",
    "        ) + WhiteKernel(1, noise_level_bounds='fixed')#(0.001, 1000))\n",
    "    )\n",
    "\n",
    "else:\n",
    "    ntk_1 = (\n",
    "        ConstantKernel(\n",
    "            constant_value=1, \n",
    "            constant_value_bounds=(1e-9, 1e2)\n",
    "        ) * \n",
    "        NTK(depth=ntk_depth[0], c=2, \n",
    "            bias=1e-1, \n",
    "            bias_bounds=(1e-9, 1e0)\n",
    "        ) \n",
    "    )\n",
    "\n",
    "    ntk_2 = (\n",
    "        ConstantKernel(\n",
    "            constant_value=1, \n",
    "            constant_value_bounds=(1e-9, 1e2)\n",
    "        ) * \n",
    "        NTK(depth=ntk_depth[1], c=2, \n",
    "            bias=1e-1, \n",
    "            bias_bounds=(1e-9, 1e0)\n",
    "        ) \n",
    "    )\n",
    "\n",
    "    lpk = (\n",
    "        ConstantKernel(\n",
    "            constant_value=0.224**2, \n",
    "            constant_value_bounds=c_val_bounds\n",
    "        ) * \n",
    "        Matern(\n",
    "            nu=1/2,\n",
    "            length_scale=np.array([1 for i in range(0,n)]), # anisotropic true -> trying to fit product of laplace kernels with different lengthscales\n",
    "            # length_scale=1,\n",
    "            length_scale_bounds='fixed'#(1e-1, 1e3), \n",
    "        ) \n",
    "    )\n",
    "\n",
    "gp_ntk_1 = GPR(kernel=ntk_1, alpha=1e-9, normalize_y=True, n_restarts_optimizer=9, random_state=3480795)\n",
    "gp_ntk_1.fit(X_train, y_train)\n",
    "print('NTK 1    : ', gp_ntk_1.kernel_)\n",
    "mean_ntk_1 = gp_ntk_1.predict(X)\n",
    "\n",
    "gp_ntk_2 = GPR(kernel=ntk_2, alpha=1e-9, normalize_y=True, n_restarts_optimizer=9, random_state=3480795)\n",
    "gp_ntk_2.fit(X_train, y_train)\n",
    "print('NTK 2    : ', gp_ntk_2.kernel_)\n",
    "mean_ntk_2 = gp_ntk_2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1172614907714475"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_ntk_1.kernel_.get_params()['k2__noise_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_lpk = GPR(\n",
    "    kernel=lpk, \n",
    "    alpha=1e-9, \n",
    "    normalize_y=True, \n",
    "    n_restarts_optimizer=0, \n",
    "    random_state=3480795)\n",
    "\n",
    "def g(ell, gp, residual, typ, p_or_s = 'p'):\n",
    "    try:\n",
    "        gp.set_params(**{'kernel__k2__length_scale': ell})\n",
    "    except:\n",
    "        gp.set_params(**{'kernel__k1__k2__length_scale': ell})\n",
    "    \n",
    "    gp.fit(X_train, y_train)\n",
    "    mean = gp.predict(X)\n",
    "\n",
    "    if p_or_s == 's':\n",
    "        return -spearmanr(residual, y-mean)[0]\n",
    "    else:\n",
    "        return -np.corrcoef((residual)[:,0], (y-mean)[:,0])[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rona1das/Tools/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified lower bound 0.0001. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/rona1das/Tools/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified lower bound 0.0001. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/rona1das/Tools/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified lower bound 0.0001. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/rona1das/Tools/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified lower bound 0.0001. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/rona1das/Tools/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified lower bound 0.0001. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/rona1das/Tools/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified lower bound 0.0001. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/rona1das/Tools/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified lower bound 0.0001. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/rona1das/Tools/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified lower bound 0.0001. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/rona1das/Tools/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified lower bound 0.0001. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/rona1das/Tools/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified lower bound 0.0001. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "method = 'CG'\n",
    "ell_lpk_1 = optimize.minimize(g, np.array([np.random.rand()*np.random.randint(1, 1000) for i in range(0,n)]), method=method, args=(gp_lpk, y-mean_ntk_1, '1:', corrcoef_type), )#bounds=bnds(n=n))\n",
    "# for i in range(0, opt_resets):\n",
    "#     tmp = optimize.minimize(g, np.array([np.random.rand()*10 for i in range(0,n)]), method=method, args=(gp_lpk, y-mean_ntk_1, '1:', corrcoef_type), )#bounds=bnds(p=i, n=n))\n",
    "#     if tmp.fun < ell_lpk_1.fun:\n",
    "#         ell_lpk_1 = tmp \n",
    "        \n",
    "ell_lpk_2 = optimize.minimize(g, np.array([np.random.rand()*np.random.randint(1, 1000) for i in range(0,n)]), method=method, args=(gp_lpk, y-mean_ntk_2, '2:', corrcoef_type), )#bounds=bnds(n=n))\n",
    "# for i in range(0, opt_resets):\n",
    "#     tmp = optimize.minimize(g, np.array([np.random.rand()*10 for i in range(0,n)]), method=method, args=(gp_lpk, y-mean_ntk_2, '2:', corrcoef_type), )#bounds=bnds(p=i, n=n))\n",
    "#     if tmp.fun < ell_lpk_2.fun:\n",
    "#         ell_lpk_2 = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: -0.6476140397662943\n",
       "     jac: array([0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.7252903e-08])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 5\n",
       "     nit: 0\n",
       "    njev: 1\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([527.20076786, 677.1671918 ,  88.90249654,  17.57145693])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ell_lpk_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: -0.9554766692016651\n",
       "     jac: array([3.7252903e-08, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 5\n",
       "     nit: 0\n",
       "    njev: 1\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([ 25.72753484, 247.20882496, 526.47507061, 149.05391671])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ell_lpk_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68b02c908e2cdb95db1fe9ab6c7ce5e7b7519642826f3cbd5d028e2ea906a416"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

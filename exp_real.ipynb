{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from sklearn import metrics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_experiment(data, depths, alpha=1e-5):\n",
    "    \"\"\"\n",
    "    Data format := `[X_train, y_train, X_test, y_test, norm : bool, noise : bool, name : str]`\n",
    "\n",
    "    Outputs dictionary containing `dataset`, `means`, `kernel`, \n",
    "    `ntk`, `lap`, and `gaus` information\n",
    "    \"\"\"\n",
    "    norm = data[-3]\n",
    "    noise = data[-2]\n",
    "    name = data[-1]\n",
    "\n",
    "    print(f'\\n{name} :\\nnorm  = {norm}\\nnoise = {noise}\\ndepth = {depths}')\n",
    "\n",
    "    exp_data = {}\n",
    "\n",
    "\n",
    "    means_n = []\n",
    "    for depth in depths:\n",
    "\n",
    "\n",
    "        #########################\n",
    "        # Neural tangent Kernel #\n",
    "        #########################\n",
    "\n",
    "\n",
    "        ntk = (\n",
    "            ConstantKernel(constant_value=1) + \n",
    "            NTK(depth=depth, bias=0.1)\n",
    "        )\n",
    "\n",
    "        if noise:\n",
    "            ntk += WhiteKernel(noise_level=0.1)\n",
    "\n",
    "        gp_n = GPR(kernel=ntk, alpha=alpha, normalize_y=True,\n",
    "            n_restarts_optimizer=9, random_state=29834057)\n",
    "\n",
    "        gp_n.fit(data[0], data[1])\n",
    "        mean_n = gp_n.predict(data[2])\n",
    "        print(gp_n.kernel_)\n",
    "\n",
    "\n",
    "        #########################\n",
    "        #         Data          #\n",
    "        #########################\n",
    "\n",
    "\n",
    "        if noise: \n",
    "            const_val_n = gp_n.kernel_.get_params()['k1__k1__constant_value']\n",
    "            noise_lvl_n = gp_n.kernel_.get_params()['k2__noise_level']\n",
    "            bias = gp_n.kernel_.get_params()['k1__k2__bias']\n",
    "        else:\n",
    "            const_val_n = gp_n.kernel_.get_params()['k1__constant_value']\n",
    "            noise_lvl_n = None\n",
    "            bias = gp_n.kernel_.get_params()['k2__bias']\n",
    "\n",
    "        means_n.append(mean_n.ravel())\n",
    "\n",
    "        exp_data['kernel'] = {\n",
    "            f'ntk_{depth}' : {\n",
    "                'C' : const_val_n,\n",
    "                'W' : noise_lvl_n,\n",
    "                'depth' : depths,\n",
    "                'bias' : bias\n",
    "            }\n",
    "        }\n",
    "        exp_data[f'ntk_{depth}'] = {\n",
    "            'rmse' : metrics.mean_squared_error(data[3].ravel(), mean_n.ravel(), squared=False),\n",
    "            'r2' : metrics.r2_score(data[3].ravel(), mean_n.ravel())\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #########################\n",
    "    #   Lap + Gaus Kernel   #\n",
    "    #########################    \n",
    "\n",
    "\n",
    "    lap = (\n",
    "        ConstantKernel(constant_value=1) + \n",
    "        Matern(nu=1/2, length_scale=1)\n",
    "    )\n",
    "\n",
    "    gaus = (\n",
    "        ConstantKernel(constant_value=1) + \n",
    "        Matern(nu=np.inf, length_scale=1)\n",
    "    )\n",
    "\n",
    "    if noise:\n",
    "        lap += WhiteKernel(noise_level=0.1)\n",
    "        gaus += WhiteKernel(noise_level=0.1)\n",
    "\n",
    "\n",
    "    gp_l = GPR(kernel=lap, alpha=alpha, normalize_y=True,\n",
    "        n_restarts_optimizer=9, random_state=29834057)\n",
    "\n",
    "    gp_g = GPR(kernel=gaus, alpha=alpha, normalize_y=True,\n",
    "        n_restarts_optimizer=9, random_state=29834057)\n",
    "\n",
    "\n",
    "    gp_l.fit(data[0], data[1])\n",
    "    mean_l = gp_l.predict(data[2])\n",
    "    print(gp_l.kernel_)\n",
    "\n",
    "    gp_g.fit(data[0], data[1])\n",
    "    mean_g = gp_g.predict(data[2])\n",
    "    print(gp_g.kernel_)\n",
    "\n",
    "\n",
    "    #########################\n",
    "    #         Data          #\n",
    "    #########################\n",
    "\n",
    "\n",
    "    if noise: \n",
    "        const_val_l = gp_l.kernel_.get_params()['k1__k1__constant_value']\n",
    "        const_val_g = gp_g.kernel_.get_params()['k1__k1__constant_value']\n",
    "\n",
    "        noise_lvl_l = gp_l.kernel_.get_params()['k2__noise_level']\n",
    "        noise_lvl_g = gp_g.kernel_.get_params()['k2__noise_level']\n",
    "\n",
    "        ell_l = gp_l.kernel_.get_params()['k1__k2__length_scale']\n",
    "        ell_g = gp_g.kernel_.get_params()['k1__k2__length_scale']\n",
    "    else:\n",
    "        const_val_l = gp_l.kernel_.get_params()['k1__constant_value']\n",
    "        const_val_g = gp_g.kernel_.get_params()['k1__constant_value']\n",
    "\n",
    "        noise_lvl_l = None\n",
    "        noise_lvl_g = None\n",
    "        \n",
    "        ell_l = gp_l.kernel_.get_params()['k2__length_scale']\n",
    "        ell_g = gp_g.kernel_.get_params()['k2__length_scale']\n",
    "\n",
    "\n",
    "    exp_data['dataset'] = {\n",
    "        'name' : name, \n",
    "        'norm' : norm,\n",
    "        'noise': noise,\n",
    "        'test' : [data[2], data[3]]\n",
    "    }\n",
    "\n",
    "    exp_data['means'] = (*means_n, mean_l.ravel(), mean_g.ravel())\n",
    "\n",
    "\n",
    "    exp_data['kernel'] = {\n",
    "        'lap' : {\n",
    "            'C' : const_val_l,\n",
    "            'W' : noise_lvl_l,\n",
    "            'ell' : ell_l\n",
    "        },\n",
    "        'gaus' : {\n",
    "            'C' : const_val_g,\n",
    "            'W' : noise_lvl_g,\n",
    "            'ell' : ell_g\n",
    "        }\n",
    "    }\n",
    "    exp_data['lap'] = {\n",
    "        'rmse' : metrics.mean_squared_error(data[3].ravel(), mean_l.ravel(), squared=False),\n",
    "        'r2' : metrics.r2_score(data[3].ravel(), mean_l.ravel())\n",
    "    }\n",
    "    exp_data['gaus'] = {\n",
    "        'rmse' : metrics.mean_squared_error(data[3].ravel(), mean_g.ravel(), squared=False),\n",
    "        'r2' : metrics.r2_score(data[3].ravel(), mean_g.ravel())\n",
    "    }\n",
    "\n",
    "    return exp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [X_train, y_train, X_test, y_test, norm : bool, noise : bool, name : str]\n",
    "datasets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete = pd.read_csv('./real_world_data/concrete.csv', header=0)\n",
    "\n",
    "names_c = concrete.columns\n",
    "\n",
    "X = concrete.drop(names_c[-1], axis=1)\n",
    "y = concrete[names_c[-1]]\n",
    "\n",
    "X_t = np.zeros_like(X)\n",
    "for i in range(0, X.shape[1]):\n",
    "    X_t[:,i] = (X[:,i] - np.mean(X[:,i])) / np.std(X[:,i])\n",
    "\n",
    "y_t = y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_t, y_t, test_size=0.25, random_state=13450978)\n",
    "\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, False, 'Concrete'])\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, True, 'Concrete'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalize(X_t, axis=1), y_t, test_size=0.25, random_state=13450978)\n",
    "\n",
    "datasets.append([X_train, y_train, X_test, y_test, True, False, 'Concrete'])\n",
    "datasets.append([X_train, y_train, X_test, y_test, True, True, 'Concrete'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_fires = pd.read_csv('./real_world_data/forestfires.csv', header=0)\n",
    "forest_fires.drop(['month', 'day'], axis=1, inplace=True)\n",
    "\n",
    "names_f = forest_fires.columns\n",
    "\n",
    "X = forest_fires.drop('area', axis=1)\n",
    "y = forest_fires['area']\n",
    "\n",
    "X_t = np.zeros_like(X)\n",
    "for i in range(0, X.shape[1]):\n",
    "    X_t[:,i] = (X[:,i] - np.mean(X[:,i])) / np.std(X[:,i])\n",
    "\n",
    "y_t = np.log(y + 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_t, y_t, test_size=0.25, random_state=13450978)\n",
    "\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, False, 'Concrete'])\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, True, 'Concrete'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalize(X_t, axis=1), y_t, test_size=0.25, random_state=13450978)\n",
    "\n",
    "datasets.append([X_train, y_train, X_test, y_test, True, False, 'Concrete'])\n",
    "datasets.append([X_train, y_train, X_test, y_test, True, True, 'Concrete'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [\n",
    "    [\"Concrete\", \"Forest Fires\"],\n",
    "    ['rmse', 'r2'],\n",
    "    [False, True],  # Noise\n",
    "]\n",
    "\n",
    "index = pd.MultiIndex.from_product(\n",
    "    arrays, names=['Dataset', 'Metric', 'Noise'])\n",
    "\n",
    "\n",
    "df_rd = pd.DataFrame(\n",
    "    index=index,\n",
    "    columns=['NTK D=3', 'NTK D=25', 'NTK D=100', 'Laplace', 'Gaussian']\n",
    ")\n",
    "\n",
    "df_sd = pd.DataFrame(\n",
    "    index=index,\n",
    "    columns=['NTK D=3', 'NTK D=25', 'NTK D=100', 'Laplace', 'Gaussian']\n",
    ")\n",
    "\n",
    "df_rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_outputs = []\n",
    "depths = (3, 25, 100)\n",
    "for data in datasets:\n",
    "    experiment_outputs.append(real_experiment(data, depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(experiment_outputs, 'exp_real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_data('exp_real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in experiment_outputs:\n",
    "    name = exp['dataset']['name']\n",
    "    noise = exp['dataset']['noise']\n",
    "\n",
    "\n",
    "    # if exp['dataset']['norm']:\n",
    "    #     for depth in depths:\n",
    "    #         df_sd[f'NTK D={depth}'][name, 'rmse', noise] = exp[f'ntk_{depth}']['rmse']\n",
    "    #         df_sd[f'NTK D={depth}'][name, 'r2', noise] = exp[f'ntk_{depth}']['r2']\n",
    "        \n",
    "    #     df_sd['Laplace'][name, 'rmse', noise] = exp['lap']['rmse']\n",
    "    #     df_sd['Laplace'][name, 'r2', noise] = exp['lap']['r2']\n",
    "    #     df_sd['Gaussian'][name, 'rmse', noise] = exp['gaus']['rmse']\n",
    "    #     df_sd['Gaussian'][name, 'r2', noise] = exp['gaus']['r2']\n",
    "    # else:\n",
    "    #     for depth in depths:\n",
    "    #         df_rd[f'NTK D={depth}'][name, 'rmse', noise] = exp[f'ntk_{depth}']['rmse']\n",
    "    #         df_rd[f'NTK D={depth}'][name, 'r2', noise] = exp[f'ntk_{depth}']['r2']\n",
    "        \n",
    "    #     df_rd['Laplace'][name, 'rmse', noise] = exp['lap']['rmse']\n",
    "    #     df_rd['Laplace'][name, 'r2', noise] = exp['lap']['r2']\n",
    "    #     df_rd['Gaussian'][name, 'rmse', noise] = exp['gaus']['rmse']\n",
    "    #     df_rd['Gaussian'][name, 'r2', noise] = exp['gaus']['r2']\n",
    "\n",
    "    if exp['dataset']['norm']:\n",
    "        for depth in depths:\n",
    "            df_sd[f'NTK D={depth}'][name, 'rmse', noise] = exp[f'ntk_{depth}']['rmse']\n",
    "            df_sd[f'NTK D={depth}'][name, 'r2', noise] =\n",
    "        \n",
    "        df_sd['Laplace'][name, 'rmse', noise] = exp['lap']['rmse']\n",
    "        df_sd['Laplace'][name, 'r2', noise] = exp['lap']['r2']\n",
    "        df_sd['Gaussian'][name, 'rmse', noise] = exp['gaus']['rmse']\n",
    "        df_sd['Gaussian'][name, 'r2', noise] = exp['gaus']['r2']\n",
    "    else:\n",
    "        for depth in depths:\n",
    "            df_rd[f'NTK D={depth}'][name, 'rmse', noise] = exp[f'ntk_{depth}']['rmse']\n",
    "            df_rd[f'NTK D={depth}'][name, 'r2', noise] = exp[f'ntk_{depth}']['r2']\n",
    "        \n",
    "        df_rd['Laplace'][name, 'rmse', noise] = exp['lap']['rmse']\n",
    "        df_rd['Laplace'][name, 'r2', noise] = exp['lap']['r2']\n",
    "        df_rd['Gaussian'][name, 'rmse', noise] = exp['gaus']['rmse']\n",
    "        df_rd['Gaussian'][name, 'r2', noise] = exp['gaus']['r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_data(experiment_outputs, 'exp_real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sd"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68b02c908e2cdb95db1fe9ab6c7ce5e7b7519642826f3cbd5d028e2ea906a416"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from sklearn import metrics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_experiment(data, depths, alpha=1e-5):\n",
    "    \"\"\"\n",
    "    Data format := `[X_train, y_train, X_test, y_test, norm : bool, noise : bool, name : str]`\n",
    "\n",
    "    Outputs dictionary containing `dataset`, `means`, `kernel`, \n",
    "    `ntk`, `lap`, and `gaus` information\n",
    "    \"\"\"\n",
    "    norm = data[-3]\n",
    "    noise = data[-2]\n",
    "    name = data[-1]\n",
    "\n",
    "    print(f'\\n{name} :\\nnorm  = {norm}\\nnoise = {noise}\\ndepth = {depths}')\n",
    "\n",
    "    exp_data = {}\n",
    "\n",
    "\n",
    "    means_n = []\n",
    "    for depth in depths:\n",
    "\n",
    "\n",
    "        #########################\n",
    "        # Neural tangent Kernel #\n",
    "        #########################\n",
    "\n",
    "\n",
    "        ntk = (\n",
    "            ConstantKernel(constant_value=1) + \n",
    "            NTK(depth=depth, bias=0.1)\n",
    "        )\n",
    "\n",
    "        if noise:\n",
    "            ntk += WhiteKernel(noise_level=0.1)\n",
    "\n",
    "        gp_n = GPR(kernel=ntk, alpha=alpha, normalize_y=True,\n",
    "            n_restarts_optimizer=9, random_state=29834057)\n",
    "\n",
    "        gp_n.fit(data[0], data[1])\n",
    "        mean_n = gp_n.predict(data[2])\n",
    "        print(gp_n.kernel_)\n",
    "\n",
    "\n",
    "        #########################\n",
    "        #         Data          #\n",
    "        #########################\n",
    "\n",
    "\n",
    "        if noise: \n",
    "            const_val_n = gp_n.kernel_.get_params()['k1__k1__constant_value']\n",
    "            noise_lvl_n = gp_n.kernel_.get_params()['k2__noise_level']\n",
    "            bias = gp_n.kernel_.get_params()['k1__k2__bias']\n",
    "        else:\n",
    "            const_val_n = gp_n.kernel_.get_params()['k1__constant_value']\n",
    "            noise_lvl_n = None\n",
    "            bias = gp_n.kernel_.get_params()['k2__bias']\n",
    "\n",
    "        means_n.append(mean_n.ravel())\n",
    "\n",
    "        exp_data['kernel'] = {\n",
    "            f'ntk_{depth}' : {\n",
    "                'C' : const_val_n,\n",
    "                'W' : noise_lvl_n,\n",
    "                'depth' : depths,\n",
    "                'bias' : bias\n",
    "            }\n",
    "        }\n",
    "        exp_data[f'ntk_{depth}'] = {\n",
    "            'rmse' : metrics.mean_squared_error(data[3].ravel(), mean_n.ravel(), squared=False),\n",
    "            'r2' : metrics.r2_score(data[3].ravel(), mean_n.ravel())\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #########################\n",
    "    #   Lap + Gaus Kernel   #\n",
    "    #########################    \n",
    "\n",
    "\n",
    "    lap = (\n",
    "        ConstantKernel(constant_value=1) + \n",
    "        Matern(nu=1/2, length_scale=1)\n",
    "    )\n",
    "\n",
    "    gaus = (\n",
    "        ConstantKernel(constant_value=1) + \n",
    "        Matern(nu=np.inf, length_scale=1)\n",
    "    )\n",
    "\n",
    "    if noise:\n",
    "        ntk += WhiteKernel(noise_level=0.1)\n",
    "        lap += WhiteKernel(noise_level=0.1)\n",
    "        gaus += WhiteKernel(noise_level=0.1)\n",
    "\n",
    "\n",
    "    gp_l = GPR(kernel=lap, alpha=alpha, normalize_y=True,\n",
    "        n_restarts_optimizer=9, random_state=29834057)\n",
    "\n",
    "    gp_g = GPR(kernel=gaus, alpha=alpha, normalize_y=True,\n",
    "        n_restarts_optimizer=9, random_state=29834057)\n",
    "\n",
    "\n",
    "    gp_l.fit(data[0], data[1])\n",
    "    mean_l = gp_l.predict(data[2])\n",
    "    print(gp_l.kernel_)\n",
    "\n",
    "    gp_g.fit(data[0], data[1])\n",
    "    mean_g = gp_g.predict(data[2])\n",
    "    print(gp_g.kernel_)\n",
    "\n",
    "\n",
    "    #########################\n",
    "    #         Data          #\n",
    "    #########################\n",
    "\n",
    "\n",
    "    if noise: \n",
    "        const_val_l = gp_l.kernel_.get_params()['k1__k1__constant_value']\n",
    "        const_val_g = gp_g.kernel_.get_params()['k1__k1__constant_value']\n",
    "\n",
    "        noise_lvl_l = gp_l.kernel_.get_params()['k2__noise_level']\n",
    "        noise_lvl_g = gp_g.kernel_.get_params()['k2__noise_level']\n",
    "\n",
    "        ell_l = gp_l.kernel_.get_params()['k1__k2__length_scale']\n",
    "        ell_g = gp_g.kernel_.get_params()['k1__k2__length_scale']\n",
    "    else:\n",
    "        const_val_l = gp_l.kernel_.get_params()['k1__constant_value']\n",
    "        const_val_g = gp_g.kernel_.get_params()['k1__constant_value']\n",
    "\n",
    "        noise_lvl_l = None\n",
    "        noise_lvl_g = None\n",
    "        \n",
    "        ell_l = gp_l.kernel_.get_params()['k2__length_scale']\n",
    "        ell_g = gp_g.kernel_.get_params()['k2__length_scale']\n",
    "\n",
    "\n",
    "    exp_data['dataset'] = {\n",
    "        'name' : name, \n",
    "        'norm' : norm,\n",
    "        'noise': noise,\n",
    "        'test' : [data[2], data[3]]\n",
    "    }\n",
    "\n",
    "    exp_data['means'] = (*means_n, mean_l.ravel(), mean_g.ravel())\n",
    "\n",
    "\n",
    "    exp_data['kernel'] = {\n",
    "        'lap' : {\n",
    "            'C' : const_val_l,\n",
    "            'W' : noise_lvl_l,\n",
    "            'ell' : ell_l\n",
    "        },\n",
    "        'gaus' : {\n",
    "            'C' : const_val_g,\n",
    "            'W' : noise_lvl_g,\n",
    "            'ell' : ell_g\n",
    "        }\n",
    "    }\n",
    "    exp_data['lap'] = {\n",
    "        'rmse' : metrics.mean_squared_error(data[3].ravel(), mean_l.ravel(), squared=False),\n",
    "        'r2' : metrics.r2_score(data[3].ravel(), mean_l.ravel())\n",
    "    }\n",
    "    exp_data['gaus'] = {\n",
    "        'rmse' : metrics.mean_squared_error(data[3].ravel(), mean_g.ravel(), squared=False),\n",
    "        'r2' : metrics.r2_score(data[3].ravel(), mean_g.ravel())\n",
    "    }\n",
    "\n",
    "    return exp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [X_train, y_train, X_test, y_test, norm : bool, noise : bool, name : str]\n",
    "datasets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete = pd.read_csv('./real_world_data/concrete.csv', header=0)\n",
    "\n",
    "names_c = concrete.columns\n",
    "\n",
    "X = concrete.drop(names_c[-1], axis=1)\n",
    "y = concrete[names_c[-1]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13450978)\n",
    "\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, False, 'Concrete'])\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, True, 'Concrete'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalize(X, axis=1), y, test_size=0.25, random_state=13450978)\n",
    "\n",
    "datasets.append([X_train, y_train, X_test, y_test, True, False, 'Concrete'])\n",
    "datasets.append([X_train, y_train, X_test, y_test, True, True, 'Concrete'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_fires = pd.read_csv('./real_world_data/forestfires.csv', header=0)\n",
    "forest_fires.drop(['month', 'day'], axis=1, inplace=True)\n",
    "\n",
    "names_f = forest_fires.columns\n",
    "\n",
    "X = forest_fires.drop('area', axis=1)\n",
    "y = forest_fires['area']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=879631245)\n",
    "\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, False, 'Forest Fires'])\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, True, 'Forest Fires'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalize(X, axis=1), y, test_size=0.25, random_state=879631245)\n",
    "\n",
    "datasets.append([X_train, y_train, X_test, y_test, True, False, 'Forest Fires'])\n",
    "datasets.append([X_train, y_train, X_test, y_test, True, True, 'Forest Fires'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NTK D=3</th>\n",
       "      <th>NTK D=25</th>\n",
       "      <th>NTK D=100</th>\n",
       "      <th>Laplace</th>\n",
       "      <th>Gaussian</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Noise</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Concrete</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">rmse</th>\n",
       "      <th>False</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">r2</th>\n",
       "      <th>False</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Forest Fires</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">rmse</th>\n",
       "      <th>False</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">r2</th>\n",
       "      <th>False</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          NTK D=3 NTK D=25 NTK D=100 Laplace Gaussian\n",
       "Dataset      Metric Noise                                            \n",
       "Concrete     rmse   False     NaN      NaN       NaN     NaN      NaN\n",
       "                    True      NaN      NaN       NaN     NaN      NaN\n",
       "             r2     False     NaN      NaN       NaN     NaN      NaN\n",
       "                    True      NaN      NaN       NaN     NaN      NaN\n",
       "Forest Fires rmse   False     NaN      NaN       NaN     NaN      NaN\n",
       "                    True      NaN      NaN       NaN     NaN      NaN\n",
       "             r2     False     NaN      NaN       NaN     NaN      NaN\n",
       "                    True      NaN      NaN       NaN     NaN      NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrays = [\n",
    "    [\"Concrete\", \"Forest Fires\"],\n",
    "    ['rmse', 'r2'],\n",
    "    [False, True],  # Noise\n",
    "]\n",
    "\n",
    "index = pd.MultiIndex.from_product(\n",
    "    arrays, names=['Dataset', 'Metric', 'Noise'])\n",
    "\n",
    "\n",
    "df_rd = pd.DataFrame(\n",
    "    index=index,\n",
    "    columns=['NTK D=3', 'NTK D=25', 'NTK D=100', 'Laplace', 'Gaussian']\n",
    ")\n",
    "\n",
    "df_sd = pd.DataFrame(\n",
    "    index=index,\n",
    "    columns=['NTK D=3', 'NTK D=25', 'NTK D=100', 'Laplace', 'Gaussian']\n",
    ")\n",
    "\n",
    "df_rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concrete :\n",
      "norm  = False\n",
      "noise = False\n",
      "depth = (3, 25, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:610: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.274**2 + NTK(depth=3, c=2.000, bias=129.560)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:610: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0387**2 + NTK(depth=25, c=2.000, bias=384.425)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:610: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/anaconda/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00316**2 + NTK(depth=100, c=2.000, bias=841.043)\n",
      "0.0847**2 + Matern(length_scale=13.5, nu=0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014**2 + Matern(length_scale=1e-05, nu=inf)\n",
      "\n",
      "Concrete :\n",
      "norm  = False\n",
      "noise = True\n",
      "depth = (3, 25, 100)\n",
      "0.0266**2 + NTK(depth=3, c=2.000, bias=443.406) + WhiteKernel(noise_level=0.0426)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:610: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.135**2 + NTK(depth=25, c=2.000, bias=1812.640) + WhiteKernel(noise_level=0.0399)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:610: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.109**2 + NTK(depth=100, c=2.000, bias=30062.447) + WhiteKernel(noise_level=0.033)\n",
      "0.291**2 + Matern(length_scale=311, nu=0.5) + WhiteKernel(noise_level=0.0453)\n",
      "0.178**2 + Matern(length_scale=113, nu=inf) + WhiteKernel(noise_level=0.0872)\n",
      "\n",
      "Concrete :\n",
      "norm  = True\n",
      "noise = False\n",
      "depth = (3, 25, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:610: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.83**2 + NTK(depth=3, c=2.000, bias=0.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:610: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.166**2 + NTK(depth=25, c=2.000, bias=0.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:610: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00957**2 + NTK(depth=100, c=2.000, bias=0.000)\n",
      "0.124**2 + Matern(length_scale=0.0118, nu=0.5)\n",
      "0.0217**2 + Matern(length_scale=3.92e-05, nu=inf)\n",
      "\n",
      "Concrete :\n",
      "norm  = True\n",
      "noise = True\n",
      "depth = (3, 25, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/thesis/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:610: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95**2 + NTK(depth=3, c=2.000, bias=0.000) + WhiteKernel(noise_level=0.185)\n"
     ]
    }
   ],
   "source": [
    "experiment_outputs = []\n",
    "depths = (3, 25, 100)\n",
    "for data in datasets:\n",
    "    experiment_outputs.append(real_experiment(data, depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in experiment_outputs:\n",
    "    name = exp['dataset']['name']\n",
    "    noise = exp['dataset']['noise']\n",
    "\n",
    "\n",
    "    if exp['dataset']['norm']:\n",
    "        for depth in depths:\n",
    "            df_sd[f'NTK D={depth}'][name, 'rmse', noise] = exp[f'ntk_{depth}']['rmse']\n",
    "            df_sd[f'NTK D={depth}'][name, 'r2', noise] = exp[f'ntk_{depth}']['r2']\n",
    "        \n",
    "        df_sd['Laplace'][name, 'rmse', noise] = exp['lap']['rmse']\n",
    "        df_sd['Laplace'][name, 'r2', noise] = exp['lap']['r2']\n",
    "        df_sd['Gaussian'][name, 'rmse', noise] = exp['gaus']['rmse']\n",
    "        df_sd['Gaussian'][name, 'r2', noise] = exp['gaus']['r2']\n",
    "    else:\n",
    "        for depth in depths:\n",
    "            df_rd[f'NTK D={depth}'][name, 'rmse', noise] = exp[f'ntk_{depth}']['rmse']\n",
    "            df_rd[f'NTK D={depth}'][name, 'r2', noise] = exp[f'ntk_{depth}']['r2']\n",
    "        \n",
    "        df_rd['Laplace'][name, 'rmse', noise] = exp['lap']['rmse']\n",
    "        df_rd['Laplace'][name, 'r2', noise] = exp['lap']['r2']\n",
    "        df_rd['Gaussian'][name, 'rmse', noise] = exp['gaus']['rmse']\n",
    "        df_rd['Gaussian'][name, 'r2', noise] = exp['gaus']['r2']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8dbd7d567f93f70199c703272456b4cf95669ac4b69cfdbc6e59ff6d42f5cd47"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

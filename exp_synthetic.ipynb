{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_friedman1, make_friedman2, make_friedman3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths=(3,25,100)\n",
    "arrays = [\n",
    "    ['Parametric', 'Ackley', 'Franke', 'Nonpoly', 'Friedman 1', 'Friedman 2', 'Friedman 3'],\n",
    "    [False, True],  # Noise\n",
    "]\n",
    "\n",
    "index = pd.MultiIndex.from_product(\n",
    "    arrays, names=[\"Dataset\", \"Noise\"])\n",
    "\n",
    "\n",
    "df_gaus_rd = pd.DataFrame(\n",
    "    index=index,\n",
    "    columns=['D3rmse', 'D25rmse',  'D100rmse', 'D3corr', 'D25corr', 'D100corr'])\n",
    "\n",
    "df_gaus_sd = pd.DataFrame(\n",
    "    index=index,\n",
    "    columns=['D3rmse', 'D25rmse',  'D100rmse', 'D3corr', 'D25corr', 'D100corr'])\n",
    "\n",
    "df_lap_rd = pd.DataFrame(\n",
    "    index=index,\n",
    "    columns=['D3rmse', 'D25rmse',  'D100rmse', 'D3corr', 'D25corr', 'D100corr'])\n",
    "\n",
    "df_lap_sd = pd.DataFrame(\n",
    "    index=index,\n",
    "    columns=['D3rmse', 'D25rmse',  'D100rmse', 'D3corr', 'D25corr', 'D100corr'])\n",
    "\n",
    "df_gaus_rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "# [X_train, y_train, X_test, y_test, norm, noise, name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Parametric'\n",
    "np.random.seed(12435908)\n",
    "noise = 0.15\n",
    "\n",
    "linear = np.linspace(0, 99, 100, dtype=int)\n",
    "train_index = np.sort(np.random.choice(linear, 50, replace=False))\n",
    "test_index = np.delete(linear, train_index)\n",
    "\n",
    "z = np.linspace(-2, 2, 100)\n",
    "t = np.linspace(-2*np.pi, 2*np.pi, 100)\n",
    "x = (z**2 + 1) * np.sin(t)\n",
    "y = (z**2 + 1) * np.cos(t)\n",
    "\n",
    "X, y, y_noisy = np.column_stack((x,y)), z.reshape(-1,1), np.random.normal(z, scale=noise).reshape(-1,1)\n",
    "\n",
    "X_train, y_train, y_train_noisy = X[train_index], y[train_index], y_noisy[train_index]\n",
    "X_norm_train = normalize(X_train, axis=1)\n",
    "\n",
    "X_test, y_test, y_test_noisy = X[test_index], y[test_index], y_noisy[test_index]\n",
    "X_norm_test = normalize(X_test, axis=1)\n",
    "\n",
    "# [X_train, y_train, X_test, y_test, norm, noise, name]\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, 0.0, name])\n",
    "datasets.append([X_norm_train, y_train, X_norm_test, y_test, True, 0.0, name])\n",
    "datasets.append([X_train, y_train_noisy, X_test, y_test_noisy, False, 0.15, name])\n",
    "datasets.append([X_norm_train, y_train_noisy, X_norm_test, y_test_noisy, True, 0.15, name])\n",
    "\n",
    "# fig, ax = plot((X, X_train), (y.ravel(), y_train_noisy), typ='data', title=r\"$z = f(x, y)$\", figsize=(8, 2.5))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize = (8,3), sharey=True)\n",
    "ax[2].remove()\n",
    "ax[2] = plt.subplot(1,3,3,projection='3d')\n",
    "ax[2].patch.set_alpha(0)\n",
    "ax[2].plot(X[:,0], X[:,1], y.ravel(), c='black')\n",
    "ax[2].scatter(X[:,0], X[:,1], y_noisy, c=y_noisy, cmap='plasma', alpha=.9)\n",
    "ax[2].set_xlabel('x')\n",
    "ax[2].set_ylabel('y')\n",
    "\n",
    "ax[1].plot(X[:,0], y.ravel(), c='black', zorder=0)\n",
    "ax[1].scatter(X[:,0], y_noisy, c=y_noisy, alpha=.7, cmap='plasma')\n",
    "ax[1].set_xlabel('x')\n",
    "# ax[1].set_ylabel('z')\n",
    "\n",
    "ax[0].plot(X[:,1], y.ravel(), c='black', zorder=0)\n",
    "ax[0].scatter(X[:,1], y_noisy, c=y_noisy, alpha=.7, cmap='plasma')\n",
    "ax[0].set_xlabel('y')\n",
    "ax[0].set_ylabel('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "fig.savefig('./exp/synth_2D/parametric/dataset.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ackley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrsize = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(10,3), subplot_kw={'projection': '3d'})\n",
    "ax = ax.ravel()\n",
    "for a in ax:\n",
    "    a.patch.set_alpha(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Ackley'\n",
    "noise = 0.75\n",
    "\n",
    "tmp1 = sample(1,7, arrsize)\n",
    "tmp2 = sample(1,7, arrsize)\n",
    "tmp3 = sample(1,7, arrsize)\n",
    "tmp4 = sample(1,7, arrsize)\n",
    "X1, Y1 = np.meshgrid(tmp1, tmp2)    \n",
    "Z1 = -20*np.exp(-0.2 * np.sqrt(0.5*(X1**2 + Y1**2))) - np.exp(0.5 *(np.cos(2*np.pi*X1) + np.cos(2*np.pi*Y1))) + np.e + 20\n",
    "X2, Y2 = np.meshgrid(tmp3, tmp4)    \n",
    "Z2 = -20*np.exp(-0.2 * np.sqrt(0.5*(X2**2 + Y2**2))) - np.exp(0.5 *(np.cos(2*np.pi*X2) + np.cos(2*np.pi*Y2))) + np.e + 20\n",
    "\n",
    "bigX1 = np.stack((X1,Y1), axis=2).reshape(-1,2)\n",
    "smolY1 = Z1.reshape(-1,1)\n",
    "bigX2 = np.stack((X2,Y2), axis=2).reshape(-1,2)\n",
    "smolY2 = Z2.reshape(-1,1)\n",
    "\n",
    "X_train, y_train, y_train_noisy = bigX1, smolY1, np.random.normal(smolY1, scale=noise).reshape(-1,1)\n",
    "X_norm_train = normalize(X_train, axis=1)\n",
    "\n",
    "X_test, y_test, y_test_noisy = bigX2, smolY2, np.random.normal(smolY2, scale=noise).reshape(-1,1)\n",
    "X_norm_test = normalize(X_test, axis=1)\n",
    "\n",
    "# [X_train, y_train, X_test, y_test, norm, noise, name]\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, 0.0, name])\n",
    "datasets.append([X_norm_train, y_train, X_norm_test, y_test, True, 0.0, name])\n",
    "datasets.append([X_train, y_train_noisy, X_test, y_test_noisy, False, 0.15, name])\n",
    "datasets.append([X_norm_train, y_train_noisy, X_norm_test, y_test_noisy, True, 0.15, name])\n",
    "\n",
    "ax[0].contourf(X1,Y1,Z1, levels=100)\n",
    "ax[0].set_title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Franke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Franke'\n",
    "noise = 0.1\n",
    "\n",
    "tmp1 = sample(-0.5,1, arrsize)\n",
    "tmp2 = sample(-0.5,1, arrsize)\n",
    "tmp3 = sample(-0.5,1, arrsize)\n",
    "tmp4 = sample(-0.5,1, arrsize)\n",
    "X1, Y1 = np.meshgrid(tmp1, tmp2)     \n",
    "Z1 = (0.75*np.exp(- (9*X1 - 2)**2/4 - (9*Y1 - 2)**2/4) + \n",
    "        0.75*np.exp(- (9*X1 + 1)**2/49 - (9*Y1 + 1)/10) +\n",
    "        0.5*np.exp(- (9*X1 - 7)**2/4  - (9*Y1 - 3)**2/4) +\n",
    "        0.2*np.exp(- (9*X1 - 4)**2    - (9*Y1 - 7)**2))\n",
    "X2, Y2 = np.meshgrid(tmp3, tmp4)     \n",
    "Z2 = (0.75*np.exp(- (9*X2 - 2)**2/4 - (9*Y2 - 2)**2/4) + \n",
    "        0.75*np.exp(- (9*X2 + 1)**2/49 - (9*Y2 + 1)/10) +\n",
    "        0.5*np.exp(- (9*X2 - 7)**2/4  - (9*Y2 - 3)**2/4) +\n",
    "        0.2*np.exp(- (9*X2 - 4)**2    - (9*Y2 - 7)**2))\n",
    "\n",
    "bigX1 = np.stack((X1,Y1), axis=2).reshape(-1,2)\n",
    "smolY1 = Z1.reshape(-1,1)\n",
    "bigX2 = np.stack((X2,Y2), axis=2).reshape(-1,2)\n",
    "smolY2 = Z2.reshape(-1,1)\n",
    "\n",
    "X_train, y_train, y_train_noisy = bigX1, smolY1, np.random.normal(smolY1, scale=noise).reshape(-1,1)\n",
    "X_norm_train = normalize(X_train, axis=1)\n",
    "\n",
    "X_test, y_test, y_test_noisy = bigX2, smolY2, np.random.normal(smolY2, scale=noise).reshape(-1,1)\n",
    "X_norm_test = normalize(X_test, axis=1)\n",
    "\n",
    "# [X_train, y_train, X_test, y_test, norm, noise, name]\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, 0.0, name])\n",
    "datasets.append([X_norm_train, y_train, X_norm_test, y_test, True, 0.0, name])\n",
    "datasets.append([X_train, y_train_noisy, X_test, y_test_noisy, False, 0.15, name])\n",
    "datasets.append([X_norm_train, y_train_noisy, X_norm_test, y_test_noisy, True, 0.15, name])\n",
    "\n",
    "ax[1].contourf(X1,Y1,Z1, levels=100)\n",
    "ax[1].set_title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonpolynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Nonpolynomial'\n",
    "noise = 1\n",
    "\n",
    "tmp1 = sample(0,2, arrsize)\n",
    "tmp2 = sample(0,2, arrsize)\n",
    "tmp3 = sample(0,2, arrsize)\n",
    "tmp4 = sample(0,2, arrsize)\n",
    "X1, Y1 = np.meshgrid(tmp1, tmp2)   \n",
    "Z1 = 1/6 * ((30+5*X1*np.sin(5*X1))*(4+np.exp(-5*Y1)) - 100)\n",
    "X2, Y2 = np.meshgrid(tmp3, tmp4)   \n",
    "Z2 = 1/6 * ((30+5*X2*np.sin(5*X2))*(4+np.exp(-5*Y2)) - 100)\n",
    "\n",
    "bigX1 = np.stack((X1,Y1), axis=2).reshape(-1,2)\n",
    "smolY1 = Z1.reshape(-1,1)\n",
    "bigX2 = np.stack((X2,Y2), axis=2).reshape(-1,2)\n",
    "smolY2 = Z2.reshape(-1,1)\n",
    "\n",
    "X_train, y_train, y_train_noisy = bigX1, smolY1, np.random.normal(smolY1, scale=noise).reshape(-1,1)\n",
    "X_norm_train = normalize(X_train, axis=1)\n",
    "\n",
    "X_test, y_test, y_test_noisy = bigX2, smolY2, np.random.normal(smolY2, scale=noise).reshape(-1,1)\n",
    "X_norm_test = normalize(X_test, axis=1)\n",
    "\n",
    "# [X_train, y_train, X_test, y_test, norm, noise, name]\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, 0.0, name])\n",
    "datasets.append([X_norm_train, y_train, X_norm_test, y_test, True, 0.0, name])\n",
    "datasets.append([X_train, y_train_noisy, X_test, y_test_noisy, False, 0.15, name])\n",
    "datasets.append([X_norm_train, y_train_noisy, X_norm_test, y_test_noisy, True, 0.15, name])\n",
    "ax[2].contourf(X1,Y1,Z1, levels=100)\n",
    "ax[2].set_title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "fig.savefig('./exp/synth_2D/2D.svg')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friedman 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Friedman 1'\n",
    "noise = 1.5\n",
    "\n",
    "X_train, y_train = make_friedman1(noise=0.0, random_state=18397425)\n",
    "_, y_train_noisy = make_friedman1(noise=noise, random_state=18397425)\n",
    "X_norm_train= normalize(X_train, axis=1)\n",
    "\n",
    "X_test, y_test = make_friedman1(noise=0.0, random_state=30189745)\n",
    "_, y_test_noisy = make_friedman1(noise=noise, random_state=30189745)\n",
    "X_norm_test= normalize(X_test, axis=1)\n",
    "\n",
    "# [X_train, y_train, X_test, y_test, norm, noise, name]\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, 0.0, name])\n",
    "datasets.append([X_norm_train, y_train, X_norm_test, y_test, True, 0.0, name])\n",
    "datasets.append([X_train, y_train_noisy, X_test, y_test_noisy, False, 0.15, name])\n",
    "datasets.append([X_norm_train, y_train_noisy, X_norm_test, y_test_noisy, True, 0.15, name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friedman 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Friedman 2'\n",
    "noise = 5\n",
    "\n",
    "X_train, y_train = make_friedman2(noise=0.0, random_state=18397425)\n",
    "_, y_train_noisy = make_friedman2(noise=noise, random_state=18397425)\n",
    "X_norm_train= normalize(X_train, axis=1)\n",
    "\n",
    "X_test, y_test = make_friedman2(noise=0.0, random_state=30189745)\n",
    "_, y_test_noisy = make_friedman2(noise=noise, random_state=30189745)\n",
    "X_norm_test= normalize(X_test, axis=1)\n",
    "\n",
    "# [X_train, y_train, X_test, y_test, norm, noise, name]\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, 0.0, name])\n",
    "datasets.append([X_norm_train, y_train, X_norm_test, y_test, True, 0.0, name])\n",
    "datasets.append([X_train, y_train_noisy, X_test, y_test_noisy, False, 0.15, name])\n",
    "datasets.append([X_norm_train, y_train_noisy, X_norm_test, y_test_noisy, True, 0.15, name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friedman 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Friedman 3'\n",
    "noise = 0.15\n",
    "\n",
    "X_train, y_train = make_friedman3(noise=0.0, random_state=18397425)\n",
    "_, y_train_noisy = make_friedman3(noise=noise, random_state=18397425)\n",
    "X_norm_train= normalize(X_train, axis=1)\n",
    "\n",
    "X_test, y_test = make_friedman3(noise=0.0, random_state=30189745)\n",
    "_, y_test_noisy = make_friedman3(noise=noise, random_state=30189745)\n",
    "X_norm_test= normalize(X_test, axis=1)\n",
    "\n",
    "# [X_train, y_train, X_test, y_test, norm, noise, name]\n",
    "datasets.append([X_train, y_train, X_test, y_test, False, 0.0, name])\n",
    "datasets.append([X_norm_train, y_train, X_norm_test, y_test, True, 0.0, name])\n",
    "datasets.append([X_train, y_train_noisy, X_test, y_test_noisy, False, 0.15, name])\n",
    "datasets.append([X_norm_train, y_train_noisy, X_norm_test, y_test_noisy, True, 0.15, name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_outputs = []\n",
    "for data in datasets:\n",
    "    for depth in (3, 25, 100):\n",
    "        experiment_outputs.append(experiment(data, depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in experiment_outputs:\n",
    "    depth = exp['kernel']['depth']\n",
    "    name = exp['dataset']['name']\n",
    "    noise = exp['dataset']['noise']\n",
    "    if exp['dataset']['norm']:\n",
    "        df_lap_sd[f'D{depth}rmse'][name, noise]\n",
    "        df_lap_sd[f'D{depth}corr'][name, noise]\n",
    "        df_gaus_sd[f'D{depth}rmse'][name, noise]\n",
    "        df_gaus_sd[f'D{depth}corr'][name, noise]\n",
    "    else:\n",
    "        df_lap_rd[f'D{depth}rmse'][name, noise]\n",
    "        df_lap_rd[f'D{depth}corr'][name, noise]\n",
    "        df_gaus_rd[f'D{depth}rmse'][name, noise]\n",
    "        df_gaus_rd[f'D{depth}corr'][name, noise]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68b02c908e2cdb95db1fe9ab6c7ce5e7b7519642826f3cbd5d028e2ea906a416"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

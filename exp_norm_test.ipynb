{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_friedman2, make_friedman3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_experiment(data, depths, alpha=1e-5):\n",
    "    \"\"\"\n",
    "    Data format := `[X_train, y_train, X_test, y_test, norm : bool, noise : bool, name : str]`\n",
    "\n",
    "    Outputs dictionary containing `dataset`, `means`, `kernel`, \n",
    "    `ntk`, `lap`, and `gaus` information\n",
    "    \"\"\"\n",
    "    norm = data[-3]\n",
    "    noise = data[-2]\n",
    "    name = data[-1]\n",
    "\n",
    "    print(f'\\n{name} :\\nnorm  = {norm}\\nnoise = {noise}\\ndepth = {depths}')\n",
    "\n",
    "    exp_data = {}\n",
    "\n",
    "\n",
    "    means_n = []\n",
    "    for depth in depths:\n",
    "\n",
    "\n",
    "        #########################\n",
    "        # Neural tangent Kernel #\n",
    "        #########################\n",
    "\n",
    "\n",
    "        ntk = (\n",
    "            ConstantKernel(constant_value=1) + \n",
    "            NTK(depth=depth, bias=0.1)\n",
    "        )\n",
    "\n",
    "        if noise:\n",
    "            ntk += WhiteKernel(noise_level=0.1)\n",
    "\n",
    "        gp_n = GPR(kernel=ntk, alpha=alpha, normalize_y=True,\n",
    "            n_restarts_optimizer=9, random_state=29834057)\n",
    "\n",
    "        gp_n.fit(data[0], data[1])\n",
    "        mean_n = gp_n.predict(data[2])\n",
    "        print(gp_n.kernel_)\n",
    "\n",
    "\n",
    "        #########################\n",
    "        #         Data          #\n",
    "        #########################\n",
    "\n",
    "\n",
    "        if noise: \n",
    "            const_val_n = gp_n.kernel_.get_params()['k1__k1__constant_value']\n",
    "            noise_lvl_n = gp_n.kernel_.get_params()['k2__noise_level']\n",
    "            bias = gp_n.kernel_.get_params()['k1__k2__bias']\n",
    "        else:\n",
    "            const_val_n = gp_n.kernel_.get_params()['k1__constant_value']\n",
    "            noise_lvl_n = None\n",
    "            bias = gp_n.kernel_.get_params()['k2__bias']\n",
    "\n",
    "        means_n.append(mean_n.ravel())\n",
    "\n",
    "        exp_data['kernel'] = {\n",
    "            f'ntk_{depth}' : {\n",
    "                'C' : const_val_n,\n",
    "                'W' : noise_lvl_n,\n",
    "                'depth' : depths,\n",
    "                'bias' : bias\n",
    "            }\n",
    "        }\n",
    "        exp_data[f'ntk_{depth}'] = {\n",
    "            'rmse' : metrics.mean_squared_error(data[3].ravel(), mean_n.ravel(), squared=False),\n",
    "            'r2' : metrics.r2_score(data[3].ravel(), mean_n.ravel())\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #########################\n",
    "    #   Lap + Gaus Kernel   #\n",
    "    #########################    \n",
    "\n",
    "\n",
    "    lap = (\n",
    "        ConstantKernel(constant_value=1) + \n",
    "        Matern(nu=1/2, length_scale=1)\n",
    "    )\n",
    "\n",
    "    gaus = (\n",
    "        ConstantKernel(constant_value=1) + \n",
    "        Matern(nu=np.inf, length_scale=1)\n",
    "    )\n",
    "\n",
    "    if noise:\n",
    "        ntk += WhiteKernel(noise_level=0.1)\n",
    "        lap += WhiteKernel(noise_level=0.1)\n",
    "        gaus += WhiteKernel(noise_level=0.1)\n",
    "\n",
    "\n",
    "    gp_l = GPR(kernel=lap, alpha=alpha, normalize_y=True,\n",
    "        n_restarts_optimizer=9, random_state=29834057)\n",
    "\n",
    "    gp_g = GPR(kernel=gaus, alpha=alpha, normalize_y=True,\n",
    "        n_restarts_optimizer=9, random_state=29834057)\n",
    "\n",
    "\n",
    "    gp_l.fit(data[0], data[1])\n",
    "    mean_l = gp_l.predict(data[2])\n",
    "    print(gp_l.kernel_)\n",
    "\n",
    "    gp_g.fit(data[0], data[1])\n",
    "    mean_g = gp_g.predict(data[2])\n",
    "    print(gp_g.kernel_)\n",
    "\n",
    "\n",
    "    #########################\n",
    "    #         Data          #\n",
    "    #########################\n",
    "\n",
    "\n",
    "    if noise: \n",
    "        const_val_l = gp_l.kernel_.get_params()['k1__k1__constant_value']\n",
    "        const_val_g = gp_g.kernel_.get_params()['k1__k1__constant_value']\n",
    "\n",
    "        noise_lvl_l = gp_l.kernel_.get_params()['k2__noise_level']\n",
    "        noise_lvl_g = gp_g.kernel_.get_params()['k2__noise_level']\n",
    "\n",
    "        ell_l = gp_l.kernel_.get_params()['k1__k2__length_scale']\n",
    "        ell_g = gp_g.kernel_.get_params()['k1__k2__length_scale']\n",
    "    else:\n",
    "        const_val_l = gp_l.kernel_.get_params()['k1__constant_value']\n",
    "        const_val_g = gp_g.kernel_.get_params()['k1__constant_value']\n",
    "\n",
    "        noise_lvl_l = None\n",
    "        noise_lvl_g = None\n",
    "        \n",
    "        ell_l = gp_l.kernel_.get_params()['k2__length_scale']\n",
    "        ell_g = gp_g.kernel_.get_params()['k2__length_scale']\n",
    "\n",
    "\n",
    "    exp_data['dataset'] = {\n",
    "        'name' : name, \n",
    "        'norm' : norm,\n",
    "        'noise': noise,\n",
    "        'test' : [data[2], data[3]]\n",
    "    }\n",
    "\n",
    "    exp_data['means'] = (*means_n, mean_l.ravel(), mean_g.ravel())\n",
    "\n",
    "\n",
    "    exp_data['kernel'] = {\n",
    "        'lap' : {\n",
    "            'C' : const_val_l,\n",
    "            'W' : noise_lvl_l,\n",
    "            'ell' : ell_l\n",
    "        },\n",
    "        'gaus' : {\n",
    "            'C' : const_val_g,\n",
    "            'W' : noise_lvl_g,\n",
    "            'ell' : ell_g\n",
    "        }\n",
    "    }\n",
    "    exp_data['lap'] = {\n",
    "        'rmse' : metrics.mean_squared_error(data[3].ravel(), mean_l.ravel(), squared=False),\n",
    "        'r2' : metrics.r2_score(data[3].ravel(), mean_l.ravel())\n",
    "    }\n",
    "    exp_data['gaus'] = {\n",
    "        'rmse' : metrics.mean_squared_error(data[3].ravel(), mean_g.ravel(), squared=False),\n",
    "        'r2' : metrics.r2_score(data[3].ravel(), mean_g.ravel())\n",
    "    }\n",
    "\n",
    "    return exp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "datasets_std = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Friedman 2'\n",
    "noise = 5\n",
    "\n",
    "X_train, y_train = make_friedman2(noise=0.0, random_state=18397425)\n",
    "_, y_train_noisy = make_friedman2(noise=noise, random_state=18397425)\n",
    "X_norm_train= normalize(X_train, axis=1)\n",
    "\n",
    "X_test, y_test = make_friedman2(noise=0.0, random_state=30189745)\n",
    "_, y_test_noisy = make_friedman2(noise=noise, random_state=30189745)\n",
    "X_norm_test= normalize(X_test, axis=1)\n",
    "\n",
    "# [X_train, y_train, X_test, y_test, X_draw, norm, noise, name]\n",
    "datasets.append([X_norm_train, y_train, X_norm_test, y_test, X_test, True, 0.0, name])\n",
    "datasets.append([X_norm_train, y_train_noisy, X_norm_test, y_test_noisy, X_test, True, 0.15, name])\n",
    "\n",
    "for i in range(0, X_train.shape[1]):\n",
    "    X_train[:,i] = (X_train[:,i] - np.mean(X_train[:,i])) / np.std(X_train[:,i])\n",
    "    X_test[:,i] = (X_test[:,i] - np.mean(X_train[:,i])) / np.std(X_train[:,i])\n",
    "\n",
    "X_norm_train = normalize(X_train, axis=1)\n",
    "X_norm_test = normalize(X_test, axis=1)\n",
    "\n",
    "datasets_std.append([X_norm_train, y_train, X_norm_test, y_test, X_test, True, 0.0, name + ' Std'])\n",
    "datasets_std.append([X_norm_train, y_train_noisy, X_norm_test, y_test_noisy, X_test, True, 0.15, name + ' Std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Friedman 3'\n",
    "noise = 5\n",
    "\n",
    "X_train, y_train = make_friedman3(noise=0.0, random_state=18397425)\n",
    "_, y_train_noisy = make_friedman3(noise=noise, random_state=18397425)\n",
    "X_norm_train= normalize(X_train, axis=1)\n",
    "\n",
    "X_test, y_test = make_friedman3(noise=0.0, random_state=30189745)\n",
    "_, y_test_noisy = make_friedman3(noise=noise, random_state=30189745)\n",
    "X_norm_test= normalize(X_test, axis=1)\n",
    "\n",
    "# [X_train, y_train, X_test, y_test, X_draw, norm, noise, name]\n",
    "datasets.append([X_norm_train, y_train, X_norm_test, y_test, X_test, True, 0.0, name])\n",
    "datasets.append([X_norm_train, y_train_noisy, X_norm_test, y_test_noisy, X_test, True, 0.15, name])\n",
    "\n",
    "for i in range(0, X_train.shape[1]):\n",
    "    X_train[:,i] = (X_train[:,i] - np.mean(X_train[:,i])) / np.std(X_train[:,i])\n",
    "    X_test[:,i] = (X_test[:,i] - np.mean(X_train[:,i])) / np.std(X_train[:,i])\n",
    "\n",
    "X_norm_train = normalize(X_train, axis=1)\n",
    "X_norm_test = normalize(X_test, axis=1)\n",
    "\n",
    "datasets_std.append([X_norm_train, y_train, X_norm_test, y_test, X_test, True, 0.0, name + ' Std'])\n",
    "datasets_std.append([X_norm_train, y_train_noisy, X_norm_test, y_test_noisy, X_test, True, 0.15, name + ' Std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = (3, 25, 100)\n",
    "experiment_output = []\n",
    "for dataset in datasets:\n",
    "    for depth in depths:\n",
    "        experiment_output.append(experiment(dataset, depth=depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = (3, 25, 100)\n",
    "experiment_output_std = []\n",
    "for dataset in datasets_std:\n",
    "    for depth in depths:\n",
    "        experiment_output_std.append(real_experiment(dataset, depth=depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths=(3,25,100)\n",
    "arrays = [\n",
    "    ['Friedman 2', 'Friedman 2 Std', 'Friedman 3', 'Friedman 3 Std'],\n",
    "    [False, True],  # Noise\n",
    "]\n",
    "\n",
    "index = pd.MultiIndex.from_product(\n",
    "    arrays, names=[\"Dataset\", \"Noise\"])\n",
    "\n",
    "\n",
    "df_gaus_sd = pd.DataFrame(\n",
    "    index=index,\n",
    "    columns=['D3rmse', 'D25rmse',  'D100rmse', 'D3corr', 'D25corr', 'D100corr'])\n",
    "\n",
    "df_lap_sd = pd.DataFrame(\n",
    "    index=index,\n",
    "    columns=['D3rmse', 'D25rmse',  'D100rmse', 'D3corr', 'D25corr', 'D100corr'])\n",
    "\n",
    "df_gaus_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in experiment_output:\n",
    "    depth = exp['kernel']['depth']\n",
    "    name = exp['dataset']['name']\n",
    "    noise = exp['dataset']['noise']\n",
    "\n",
    "    if noise==0.0: \n",
    "        noisy = False \n",
    "    else: \n",
    "        noisy = True\n",
    "\n",
    "    if name == 'Nonpolynomial':\n",
    "        name = 'Nonpoly'\n",
    "\n",
    "    if exp['dataset']['norm']:\n",
    "        df_lap_sd[f'D{depth}rmse'][name, noisy]  = exp['lap']['pred_rmse']\n",
    "        df_lap_sd[f'D{depth}corr'][name, noisy]  = exp['lap']['pred_corr']\n",
    "        df_gaus_sd[f'D{depth}rmse'][name, noisy] = exp['gaus']['pred_rmse']\n",
    "        df_gaus_sd[f'D{depth}corr'][name, noisy] = exp['gaus']['pred_corr']\n",
    "\n",
    "for exp in experiment_output_std:\n",
    "    depth = exp['kernel']['depth']\n",
    "    name = exp['dataset']['name']\n",
    "    noise = exp['dataset']['noise']\n",
    "\n",
    "    if noise==0.0: \n",
    "        noisy = False \n",
    "    else: \n",
    "        noisy = True\n",
    "\n",
    "    if name == 'Nonpolynomial':\n",
    "        name = 'Nonpoly'\n",
    "\n",
    "    if exp['dataset']['norm']:\n",
    "        df_lap_sd[f'D{depth}rmse'][name, noisy]  = exp['lap']['pred_rmse']\n",
    "        df_lap_sd[f'D{depth}corr'][name, noisy]  = exp['lap']['pred_corr']\n",
    "        df_gaus_sd[f'D{depth}rmse'][name, noisy] = exp['gaus']['pred_rmse']\n",
    "        df_gaus_sd[f'D{depth}corr'][name, noisy] = exp['gaus']['pred_corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lap_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gaus_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68b02c908e2cdb95db1fe9ab6c7ce5e7b7519642826f3cbd5d028e2ea906a416"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

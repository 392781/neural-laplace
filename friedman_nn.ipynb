{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from sklearn.datasets import make_friedman1, make_friedman2, make_friedman3\n",
    "from sklearn.neural_network import MLPRegressor as MLPR\n",
    "from scipy import optimize\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runner(\n",
    "    fried_num, noise = 0.0, norm = False, \n",
    "    ntk_depth = (3, 100),\n",
    "    nn_width = 500,\n",
    "    figs = False,\n",
    "    diagnostic=False\n",
    "    ):\n",
    "\n",
    "    if type(ntk_depth) == int:\n",
    "        ntk_depth = (ntk_depth,)\n",
    "\n",
    "    return_vals = {\n",
    "        'info' : f\"Friedman {fried_num} Noise = {noise} Norm = {norm}\",\n",
    "        'Dataset' : f'Friedman {fried_num}',\n",
    "        'Noise': False if noise == 0.0 else True,\n",
    "        'Norm' : norm\n",
    "        }\n",
    "    print(\n",
    "        return_vals['info']\n",
    "    )   \n",
    "    \n",
    "    X_init, y_init = [None, None]\n",
    "    if fried_num==1:\n",
    "        X_init, y_init = make_friedman1(noise=noise, random_state=18397425)\n",
    "    elif fried_num==2:\n",
    "        X_init, y_init = make_friedman2(noise=noise, random_state=18397425)\n",
    "    elif fried_num==3:\n",
    "        X_init, y_init = make_friedman3(noise=noise, random_state=18397425)\n",
    "    else:\n",
    "        return Exception(\"fried_num must be either 1, 2, or 3\")\n",
    "    \n",
    "    datasets = processing(X_init, y_init)\n",
    "    X, y, X_train, y_train = [None, datasets['orig'][1], None, datasets['orig train'][1]]\n",
    "\n",
    "    if norm:\n",
    "        X = datasets['norm'][0]\n",
    "        X_train = datasets['norm train'][0]\n",
    "    else:\n",
    "        X = datasets['orig'][0]\n",
    "        X_train = datasets['orig train'][0]\n",
    "\n",
    "    outputs = {}\n",
    "    for kernel_depth in ntk_depth:\n",
    "        # GAUSSIAN PROCESS\n",
    "        print('NTK : ', end='')\n",
    "        ntk = (\n",
    "            ConstantKernel(\n",
    "                constant_value=1, \n",
    "                constant_value_bounds=(1e-9, 1e2)\n",
    "            ) * \n",
    "            NTK(depth=kernel_depth, c=2, \n",
    "                bias=1e-1, \n",
    "                bias_bounds=(1e-9, 1e0)\n",
    "            ) \n",
    "        )\n",
    "\n",
    "        if noise != 0.0:\n",
    "            ntk = (\n",
    "                ConstantKernel(\n",
    "                    constant_value=1, \n",
    "                    constant_value_bounds=(1e-9, 1e2)\n",
    "                ) * \n",
    "                NTK(depth=kernel_depth, c=2, \n",
    "                    bias=1e-1, \n",
    "                    bias_bounds=(1e-9, 1e0)\n",
    "                ) + WhiteKernel()\n",
    "            )\n",
    "\n",
    "        gp_ntk = GPR(kernel=ntk, alpha=1e-9, normalize_y=True, n_restarts_optimizer=9, random_state=3480795)\n",
    "        gp_ntk.fit(X_train, y_train)\n",
    "        print(gp_ntk.kernel_, gp_ntk.get_params())\n",
    "        mean_ntk = gp_ntk.predict(X)\n",
    "\n",
    "\n",
    "\n",
    "        # NEURAL NETS\n",
    "        print('NN  : ', end='')\n",
    "        nn = MLPR(\n",
    "            hidden_layer_sizes=[nn_width for i in range(0, kernel_depth)],\n",
    "            activation='relu',\n",
    "            solver='sgd',\n",
    "            alpha=0.0,\n",
    "            learning_rate_init=0.000001,\n",
    "            verbose=diagnostic,\n",
    "            max_fun=15000,\n",
    "            max_iter=1000000,\n",
    "            tol=1e-8\n",
    "        )\n",
    "\n",
    "        nn.partial_fit(X_train, y_train.ravel())\n",
    "\n",
    "        # Random normal initialization\n",
    "        nn.loss_ = None\n",
    "        for i in range(0, len(nn.coefs_)):\n",
    "            nn.coefs_[i] = np.random.randn(*nn.coefs_[i].shape)\n",
    "        for i in range(0, len(nn.intercepts_)):\n",
    "            nn.intercepts_[i] = np.ones_like(nn.intercepts_[i])*gp_ntk.get_params()['kernel__k2__bias'] #np.random.randn(*nn.intercepts_[i].shape)\n",
    "            \n",
    "        nn.fit(X_train, y_train.ravel())\n",
    "        mean_nn = np.expand_dims(nn.predict(X), axis=1)\n",
    "\n",
    "        corr = np.corrcoef((y - mean_ntk)[:,0], (y - mean_nn)[:,0])[0,1]\n",
    "\n",
    "        if figs:\n",
    "            fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "            ax.scatter(y - mean_ntk, y - mean_nn)\n",
    "            ax.set_title(f\"Depth={kernel_depth}, NN Width={nn_width}\\n\" + \n",
    "            f\"Nois{'eless' if noise==0.0 else 'y'} {'Normalized' if norm else 'Non-normalized'} Friedman {fried_num}\")\n",
    "            ax.set_xlabel('NTK Residuals')\n",
    "            ax.set_ylabel('NN Residuals')\n",
    "            fig.tight_layout()\n",
    "\n",
    "        outputs['figs'] = (fig, ax)\n",
    "        outputs['corr'] = corr\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman 1 Noise = 0.0 Norm = True\n",
      "NTK : 0.725**2 * NTK(depth=3, c=2.000, bias=0.417) {'alpha': 1e-09, 'copy_X_train': True, 'kernel__k1': 1**2, 'kernel__k2': NTK(depth=3, c=2.000, bias=0.100), 'kernel__k1__constant_value': 1, 'kernel__k1__constant_value_bounds': (1e-09, 100.0), 'kernel__k2__depth': 3, 'kernel__k2__c': 2, 'kernel__k2__bias': 0.1, 'kernel__k2__bias_bounds': (1e-09, 1.0), 'kernel': 1**2 * NTK(depth=3, c=2.000, bias=0.100), 'n_restarts_optimizer': 9, 'normalize_y': True, 'optimizer': 'fmin_l_bfgs_b', 'random_state': 3480795}\n",
      "NN  : "
     ]
    }
   ],
   "source": [
    "# fried_num, noise = 0.0, norm = False, \n",
    "#     ntk_depth = (3, 100),\n",
    "#     nn_width = 500,\n",
    "#     figs = False,\n",
    "test_experiment = [1, 0.0, True, 3, 10000]\n",
    "test = runner(*test_experiment, figs=True, diagnostic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_init, y_init = make_friedman3(noise=noise, random_state=18397425)\n",
    "datasets = processing(X_init, y_init)\n",
    "\n",
    "X, y, X_train, y_train = [None, datasets['orig'][1], None, datasets['orig train'][1]]\n",
    "\n",
    "if norm:\n",
    "    X = datasets['norm'][0]\n",
    "    X_train = datasets['norm train'][0]\n",
    "else:\n",
    "    X = datasets['orig'][0]\n",
    "    X_train = datasets['orig train'][0]\n",
    "\n",
    "n = X.shape[1]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68b02c908e2cdb95db1fe9ab6c7ce5e7b7519642826f3cbd5d028e2ea906a416"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
